%!TEX root = ../main_article.tex

\section{Introduction}

Code search plays an important role in the software development process, which is an essential field of Software Engineering and studies the semantic similarity between natural language queries and program code. 	Recent years have witnessed a huge increment in source code. The statistic shows that more than 60 million new projects have been created only in 2020. Thus, code search engines can improve the development efficiency of program developers, enabling them to search for existing code or examples of some application programming interface (API), instead of “rebuilding wheels”. 

As deep learning has grown by leaps and bounds in recent years, a number of methods have been proposed in code search. such as Recurrent Neural Network (RNN) based models (\citealp{DeepCS}), Convolutional Neural Network (CNN) based models (\citealp{CQIL, ShuaiX0Y0L20}), graph based models (\citealp{, GuCM21}), and Pretrained Language Models (PLMs) based models (\citealp{CodeBERT, CoCLR, GuoLDW0022, GuoRLFT0ZDSFTDC21}). 

From the view of PLMs, all of them have well performance in code search, with complex model architecture and advanced training techniques. However, PLMs often treat code search as a downstream task, which means researchers can pretrain a model with hybrid objectives and multiple program language code data, then fine-tune it in a specific program language for code search (CITECITE). Our empirical study shows that there might be a performance decline when fine-tuning with data in multiple languages. Table 1 shows MRR comparisons between single program language fine-tuned models and multiple program language fine-tuned models. Compared with multilingual models, code information can be roughly divided into identifier information, which distinguishes code from another code written in different program languages, and sentiment information, which reveals its intention. In code search, code sentiment information is only needed, for it is matched with specific queries. Identifier information may confound model training and decrease performance when fine-tuning with multiple program language data.

% Since researchers have developed diverse complex and 
% high-performance models in all kinds of fields, 
% they focus on discovering the hidden bias, 
% which may be caused by inconsistent data distribution (\citealp{abs-2010-03240}). 
% Many fields of deep learning have suffered from all kinds of bias. 
% In (\citealp{MehrabiMSLG21}), machine learning bias can be grouped into data bias, 
% algorithm bias, and user bias. Bias methods may cause much harm, 
% such as damage diversity of results and harmful to content provider profitability. 
% Biased data can do harm to their downstream subtasks, 
% resulting in discrimination and social inequality (\citealp{AbbasiDLNSY21}). 

% However, bias in code search has not been heat debated by researchers. 
% When faced with new requirements, program developers usually 
% tend to search for existing code. A biased code search method is not worth learning, 
% lacks diversity, and may cause serious consequences, such as malicious code. 

In summary, our contributions are:
\begin{enumerate} 

\item To our best knowledge, we are the first to reveal and analyze the bias problem of code search models. We observe that state-of-the-art code search models have discriminatory behaviors toward queries or ground-truth code snippets with certain structural or semantic properties.

\item To mitigate code search bias, we propose a general de-biasing framework using re-ranking. It can be easily plugged into existing code search models.

\item We have conducted extensive experiments, and the results show that our de-biasing framework not only helps mitigate code search bias but also improves the overall ranking performance of state-of-the-art code search models.

\end{enumerate} 

% Therefore, we analyze discrepancy bias in several mainstream code search models, 
% which contain networks constructed by typical architecture such as RNN, CNN, 
% and PLMs. We aim at finding a general debias method that suits almost 
% all search methods. Networks tend to become more complex and diverse, 
% with billions of parameters. Instead of discovering clear bias prompts 
% in specific network structures, we focus on the model input, natural queries, 
% and program code, to find out what features will affect model performance. 
% Current code search methods prefer to use the similarity score of 
% high dimension high dimensional vectors of queries and code, 
% which are generated by encoders, respectively or jointly, 
% to represent semantic similarity. Thus we analyze bias prompts of queries 
% and code in the following aspects: (1) candidate code length. (2) query length. 
% (3) AST node number of candidate code. (4) AST level number of candidate code. 
% (5) number of keywords (for, if, while et al.) in candidate code. 
% (6) number of overlap words between query and code. 
% (7) Importance of words in queries.

% The code search model can be treated as a ranking model similar to recommend models. 
% We first applied debias methods in recommend systems on code search.  
% According to (\citealp{LinLXL21}), we tried adding regularity loss items to the original 
% loss function to mitigate bias. However, code search models usually 
% suffer from a problem that trains locally but tests globally. 
% For example, when training a code search model, we usually 
% take minimizing the distance between a query and its correct answer as the object. 
% But when we enter a query for testing, the code search model 
% has to calculate similarity scores between it and all the candidate code. 
% We usually use MRR, which is given by Eq~\ref{mrr}, 
% to describe the performance of a code search model, 
% while the loss function during the training process is sometimes cosine similarity. 
% \begin{equation}
%     MRR = \frac{1}{Q} \sum_{i=1}^Q \frac{1}{rank_i} \label{mrr}
% \end{equation}
    
% We proposed a debias method based on re-Ranking. 
% Our work is motivated by (\citealp{AbdollahpouriBM19}). 
% The core idea is to add a debias regular term to the origin score 
% given by code search models. We use the training set as the prior knowledge. 
% For each query in the testing set, we find the most similar training queries. 
% In this process, we use CodeBERT for encoding and calculating cosine similarity. 
% Then, we can predict features of the correct answer code using prior knowledge. 
% Finally, for codes having the same features in the testing data, 
% we add the regular term for it. 



% Focus on code search bias, revealing bias prompts in queries and program code. 
% Bias in code search has not received much attention from researchers. 
% (2) Proposed a debias method based on re-Ranking, 
% taking training data as prior knowledge. 
% Experiments show that our method can mitigate bias effectively.