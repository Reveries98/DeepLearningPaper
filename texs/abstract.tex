%!TEX root = ../main_article.tex

\begin{abstract}
    Code search is a foundational task in software development, which studies semantic similarity between natural language queries and program code. Recent years have witnessed great progress made in code search. However, researchers tend to pretrain a code representation model in different program languages so that it can be used in code related downstream problems and then fine-tune it in code search with a specific program language. Our empirical study shows that there may be performance damage when fine-tuning code search in multiple program languages. We believe that it is caused by the entanglement between code identity information and code sentiment information. Therefore, we proposed two disentangling strategies. One is leveraging a generator to obtain vectors without identity information, based on the idea of GAN (Generated Neural Network). The other is to maximize the KL divergence between identity and semantic vectors.
\end{abstract}